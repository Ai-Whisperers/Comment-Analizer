# Configuraci√≥n del Sistema - Analizador de Comentarios IA

## Variables de Entorno

### Variables Obligatorias

#### OPENAI_API_KEY
```env
OPENAI_API_KEY=sk-proj-tu-clave-openai-aqui
```
- **Descripci√≥n**: Clave de API de OpenAI para acceso a GPT-4
- **Obligatorio**: ‚úÖ S√≠ - El sistema no funcionar√° sin esta clave
- **Formato**: Debe empezar con `sk-proj-` o `sk-`
- **Obtenci√≥n**: Desde [platform.openai.com/api-keys](https://platform.openai.com/api-keys)

### Variables de Configuraci√≥n IA

#### OPENAI_MODEL
```env
OPENAI_MODEL=gpt-4
```
- **Descripci√≥n**: Modelo de IA a utilizar
- **Valor por defecto**: `gpt-4`
- **Opciones**: `gpt-4`, `gpt-4-turbo`, `gpt-3.5-turbo`
- **Recomendado**: `gpt-4` para mejor calidad de an√°lisis

#### OPENAI_MAX_TOKENS
```env
OPENAI_MAX_TOKENS=4000
```
- **Descripci√≥n**: N√∫mero m√°ximo de tokens por an√°lisis
- **Valor por defecto**: `4000`
- **Rango**: 1000-8000
- **Recomendado**: 4000 para an√°lisis completos

#### OPENAI_TEMPERATURE
```env
OPENAI_TEMPERATURE=0.7
```
- **Descripci√≥n**: Nivel de creatividad del modelo IA
- **Valor por defecto**: `0.7`
- **Rango**: 0.0-1.0
- **Interpretaci√≥n**:
  - `0.0`: M√°s determin√≠stico y consistente
  - `0.7`: Balance entre creatividad y consistencia
  - `1.0`: M√°s creativo pero menos predecible

### Variables del Sistema

#### LOG_LEVEL
```env
LOG_LEVEL=INFO
```
- **Descripci√≥n**: Nivel de detalle en los logs
- **Valor por defecto**: `INFO`
- **Opciones**: `DEBUG`, `INFO`, `WARNING`, `ERROR`
- **Uso**:
  - `DEBUG`: Para desarrollo y debugging
  - `INFO`: Para producci√≥n normal
  - `WARNING`: Solo advertencias y errores
  - `ERROR`: Solo errores cr√≠ticos

#### MAX_FILE_SIZE_MB
```env
MAX_FILE_SIZE_MB=5.0
```
- **Descripci√≥n**: Tama√±o m√°ximo de archivo en MB
- **Valor por defecto**: `5.0`
- **Rango**: 1.0-50.0
- **Consideraciones**: Archivos m√°s grandes requieren m√°s memoria

#### MAX_COMMENTS
```env
MAX_COMMENTS=2000
```
- **Descripci√≥n**: N√∫mero m√°ximo de comentarios por an√°lisis
- **Valor por defecto**: `2000`
- **Rango**: 50-5000
- **Recomendado**: 1000-2000 para balance performance/costo

### Variables de Streamlit

#### STREAMLIT_PORT
```env
STREAMLIT_PORT=8501
```
- **Descripci√≥n**: Puerto para la aplicaci√≥n web
- **Valor por defecto**: `8501`
- **Rango**: 1024-65535

#### STREAMLIT_HOST
```env
STREAMLIT_HOST=localhost
```
- **Descripci√≥n**: Host de la aplicaci√≥n
- **Valor por defecto**: `localhost`
- **Opciones**: `localhost`, `0.0.0.0` (para acceso externo)

## Archivos de Configuraci√≥n

### Archivo .env (Configuraci√≥n Local)

**Ubicaci√≥n**: Ra√≠z del proyecto
**Nombre**: `.env`

```env
# === CONFIGURACI√ìN OBLIGATORIA ===
OPENAI_API_KEY=sk-proj-tu-clave-openai-aqui

# === CONFIGURACI√ìN IA ===
OPENAI_MODEL=gpt-4
OPENAI_MAX_TOKENS=4000
OPENAI_TEMPERATURE=0.7

# === CONFIGURACI√ìN SISTEMA ===
LOG_LEVEL=INFO
MAX_FILE_SIZE_MB=5.0
MAX_COMMENTS=2000

# === CONFIGURACI√ìN STREAMLIT ===
STREAMLIT_PORT=8501
STREAMLIT_HOST=localhost

# === CONFIGURACI√ìN AVANZADA ===
# Timeout para llamadas a OpenAI (segundos)
OPENAI_TIMEOUT=300

# N√∫mero de reintentos en caso de error
OPENAI_MAX_RETRIES=3

# Tiempo de espera entre reintentos (segundos)  
OPENAI_RETRY_DELAY=2
```

### Configuraci√≥n Streamlit

#### .streamlit/config.toml

**Ubicaci√≥n**: `.streamlit/config.toml`

```toml
[theme]
# Colores del tema
primaryColor = "#8B5CF6"                # Purple para botones principales
backgroundColor = "#0f1419"             # Fondo oscuro principal
secondaryBackgroundColor = "#1c2128"    # Fondo secundario (sidebar, etc.)
textColor = "#e6edf3"                   # Color del texto principal

[server]
# Configuraci√≥n del servidor
port = 8501
address = "localhost"
maxUploadSize = 50                      # MB - Tama√±o m√°ximo de archivos
enableCORS = false
enableXsrfProtection = true

[browser]
# Configuraci√≥n del navegador
gatherUsageStats = false                # No enviar estad√≠sticas a Streamlit
serverPort = 8501
serverAddress = "localhost"

[global]
# Configuraci√≥n global
developmentMode = false
logLevel = "info"
```

#### .streamlit/secrets.toml (Para Streamlit Cloud)

**Ubicaci√≥n**: `.streamlit/secrets.toml`
**Uso**: Solo para despliegue en Streamlit Cloud

```toml
# Secrets para Streamlit Cloud
OPENAI_API_KEY = "sk-proj-tu-clave-openai-aqui"
OPENAI_MODEL = "gpt-4"
LOG_LEVEL = "INFO"
MAX_FILE_SIZE_MB = "5.0"
MAX_COMMENTS = "2000"
```

### config.py (Configuraci√≥n Centralizada)

El archivo `config.py` unifica toda la configuraci√≥n:

```python
import os
from typing import Dict, Any
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

def get_config() -> Dict[str, Any]:
    """Obtener configuraci√≥n unificada del sistema"""
    return {
        # OpenAI Configuration
        'openai_api_key': os.getenv('OPENAI_API_KEY', ''),
        'openai_model': os.getenv('OPENAI_MODEL', 'gpt-4'),
        'openai_max_tokens': int(os.getenv('OPENAI_MAX_TOKENS', '4000')),
        'openai_temperature': float(os.getenv('OPENAI_TEMPERATURE', '0.7')),
        'openai_timeout': int(os.getenv('OPENAI_TIMEOUT', '300')),
        'openai_max_retries': int(os.getenv('OPENAI_MAX_RETRIES', '3')),
        'openai_retry_delay': int(os.getenv('OPENAI_RETRY_DELAY', '2')),
        
        # System Configuration
        'log_level': os.getenv('LOG_LEVEL', 'INFO'),
        'max_file_size_mb': float(os.getenv('MAX_FILE_SIZE_MB', '5.0')),
        'max_comments': int(os.getenv('MAX_COMMENTS', '2000')),
        
        # Streamlit Configuration
        'streamlit_port': int(os.getenv('STREAMLIT_PORT', '8501')),
        'streamlit_host': os.getenv('STREAMLIT_HOST', 'localhost'),
        
        # Cache Configuration
        'enable_cache': os.getenv('ENABLE_CACHE', 'true').lower() == 'true',
        'cache_ttl': int(os.getenv('CACHE_TTL', '3600')),  # 1 hour
        
        # Performance Configuration
        'batch_size': int(os.getenv('BATCH_SIZE', '100')),
        'processing_timeout': int(os.getenv('PROCESSING_TIMEOUT', '600')),
    }

# Configuraci√≥n global
config = get_config()
```

## Configuraciones por Entorno

### Desarrollo Local

```env
# .env para desarrollo
OPENAI_API_KEY=sk-proj-tu-clave-desarrollo
OPENAI_MODEL=gpt-4
LOG_LEVEL=DEBUG
MAX_FILE_SIZE_MB=2.0
MAX_COMMENTS=100
STREAMLIT_HOST=localhost
ENABLE_CACHE=false
```

### Staging/Testing

```env
# .env para testing
OPENAI_API_KEY=sk-proj-tu-clave-testing
OPENAI_MODEL=gpt-4
LOG_LEVEL=INFO
MAX_FILE_SIZE_MB=5.0
MAX_COMMENTS=500
STREAMLIT_HOST=0.0.0.0
ENABLE_CACHE=true
```

### Producci√≥n

```env
# .env para producci√≥n
OPENAI_API_KEY=sk-proj-tu-clave-produccion
OPENAI_MODEL=gpt-4
OPENAI_MAX_TOKENS=4000
LOG_LEVEL=WARNING
MAX_FILE_SIZE_MB=10.0
MAX_COMMENTS=2000
STREAMLIT_HOST=0.0.0.0
ENABLE_CACHE=true
OPENAI_TIMEOUT=600
```

## Configuraci√≥n para Diferentes Casos de Uso

### An√°lisis R√°pido (Pocos Comentarios)

```env
# Optimizado para < 100 comentarios
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_MAX_TOKENS=2000
OPENAI_TEMPERATURE=0.5
MAX_COMMENTS=100
BATCH_SIZE=50
```

### An√°lisis Profundo (Muchos Comentarios)

```env
# Optimizado para 1000+ comentarios
OPENAI_MODEL=gpt-4
OPENAI_MAX_TOKENS=6000
OPENAI_TEMPERATURE=0.7
MAX_COMMENTS=2000
BATCH_SIZE=200
OPENAI_TIMEOUT=900
```

### An√°lisis Econ√≥mico (Reducir Costos)

```env
# Optimizado para minimizar costo
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_MAX_TOKENS=3000
MAX_COMMENTS=500
BATCH_SIZE=100
```

## Monitoreo y Logging

### Configuraci√≥n de Logging

```python
# logging.conf
[loggers]
keys=root,openai,streamlit

[handlers]
keys=consoleHandler,fileHandler

[formatters]
keys=simpleFormatter,detailedFormatter

[logger_root]
level=INFO
handlers=consoleHandler,fileHandler

[logger_openai]
level=DEBUG
handlers=fileHandler
qualname=openai
propagate=0

[handler_consoleHandler]
class=StreamHandler
level=INFO
formatter=simpleFormatter
args=(sys.stdout,)

[handler_fileHandler]
class=FileHandler
level=DEBUG
formatter=detailedFormatter
args=('app.log',)

[formatter_simpleFormatter]
format=%(asctime)s - %(name)s - %(levelname)s - %(message)s

[formatter_detailedFormatter]
format=%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s
```

### Variables de Monitoreo

```env
# Logging avanzado
LOG_FILE=app.log
LOG_MAX_SIZE=10MB
LOG_BACKUP_COUNT=5
ENABLE_PERFORMANCE_LOGGING=true
ENABLE_OPENAI_LOGGING=true
```

## Seguridad

### Variables de Seguridad

```env
# Configuraci√≥n de seguridad
ENABLE_AUTH=false                       # Para futuras implementaciones
SESSION_TIMEOUT=3600                    # Timeout de sesi√≥n en segundos
MAX_CONCURRENT_ANALYSES=5               # An√°lisis concurrentes por usuario
RATE_LIMIT_REQUESTS_PER_MINUTE=60      # L√≠mite de requests por minuto
```

### Mejores Pr√°cticas de Seguridad

#### 1. Manejo de API Keys
```bash
# NUNCA hagas commit de API keys
echo ".env" >> .gitignore
echo ".streamlit/secrets.toml" >> .gitignore

# Usar variables de entorno en producci√≥n
export OPENAI_API_KEY="sk-proj-tu-clave"

# Rotar claves regularmente
# Usar diferentes claves para dev/staging/prod
```

#### 2. Validaci√≥n de Configuraci√≥n

```python
def validar_configuracion():
    """Validar configuraci√≥n al inicio"""
    required_vars = ['OPENAI_API_KEY']
    
    for var in required_vars:
        if not os.getenv(var):
            raise ValueError(f"Variable requerida {var} no encontrada")
    
    # Validar formato de API key
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key.startswith(('sk-', 'sk-proj-')):
        raise ValueError("Formato de OPENAI_API_KEY inv√°lido")
    
    # Validar rangos num√©ricos
    max_tokens = int(os.getenv('OPENAI_MAX_TOKENS', '4000'))
    if not 1000 <= max_tokens <= 8000:
        raise ValueError("OPENAI_MAX_TOKENS debe estar entre 1000 y 8000")
```

## Configuraci√≥n de Performance

### Optimizaci√≥n de Memoria

```env
# Configuraci√≥n de memoria
STREAMLIT_SERVER_MAX_UPLOAD_SIZE=50     # MB
PANDAS_MEMORY_LIMIT=1000                # MB  
ENABLE_GARBAGE_COLLECTION=true
GC_THRESHOLD_0=700
GC_THRESHOLD_1=10
GC_THRESHOLD_2=10
```

### Configuraci√≥n de Cache

```env
# Configuraci√≥n de cach√©
ENABLE_CACHE=true
CACHE_TTL=3600                          # 1 hora
CACHE_MAX_SIZE=100                      # M√°ximo elementos
CACHE_TYPE=memory                       # memory|redis|disk
```

### Configuraci√≥n de Timeout

```env
# Timeouts del sistema
OPENAI_TIMEOUT=300                      # 5 minutos
HTTP_TIMEOUT=60                         # 1 minuto
FILE_PROCESSING_TIMEOUT=120             # 2 minutos
UI_RESPONSE_TIMEOUT=30                  # 30 segundos
```

## Configuraci√≥n Docker

### docker-compose.yml

```yaml
version: '3.8'
services:
  comment-analyzer:
    build: .
    ports:
      - "${STREAMLIT_PORT:-8501}:8501"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - MAX_FILE_SIZE_MB=${MAX_FILE_SIZE_MB:-5.0}
      - MAX_COMMENTS=${MAX_COMMENTS:-2000}
    volumes:
      - ./local-reports:/app/local-reports
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
```

### Dockerfile

```dockerfile
FROM python:3.12-slim

# Configuraci√≥n de argumentos
ARG OPENAI_API_KEY
ARG LOG_LEVEL=INFO

# Variables de entorno
ENV OPENAI_API_KEY=${OPENAI_API_KEY}
ENV LOG_LEVEL=${LOG_LEVEL}
ENV PYTHONPATH=/app
ENV STREAMLIT_SERVER_PORT=8501
ENV STREAMLIT_SERVER_ADDRESS=0.0.0.0

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8501

HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8501/_stcore/health || exit 1

CMD ["streamlit", "run", "streamlit_app.py", "--server.address=0.0.0.0"]
```

## Validaci√≥n de Configuraci√≥n

### Script de Validaci√≥n

```bash
# validate_config.py
python -c "
import os
from dotenv import load_dotenv
load_dotenv()

# Verificar variables cr√≠ticas
required_vars = {
    'OPENAI_API_KEY': 'sk-',
    'OPENAI_MODEL': ['gpt-4', 'gpt-3.5-turbo'],
    'LOG_LEVEL': ['DEBUG', 'INFO', 'WARNING', 'ERROR']
}

for var, expected in required_vars.items():
    value = os.getenv(var)
    if not value:
        print(f'‚ùå {var} no configurada')
    elif isinstance(expected, str) and not value.startswith(expected):
        print(f'‚ùå {var} formato incorrecto')  
    elif isinstance(expected, list) and value not in expected:
        print(f'‚ùå {var} valor no v√°lido: {value}')
    else:
        print(f'‚úÖ {var} configurada correctamente')

print('\\n‚úÖ Validaci√≥n de configuraci√≥n completada')
"
```

### Comando de Diagn√≥stico

```bash
# Crear script diagn√≥stico
python -c "
import streamlit as st
import openai
import pandas as pd
import sys
import os
from dotenv import load_dotenv

load_dotenv()

print('üîç DIAGN√ìSTICO DEL SISTEMA')
print('=' * 40)

# Python version
print(f'Python: {sys.version.split()[0]}')

# Package versions  
print(f'Streamlit: {st.__version__}')
print(f'OpenAI: {openai.__version__}')
print(f'Pandas: {pd.__version__}')

# Configuration
api_key = os.getenv('OPENAI_API_KEY')
print(f'API Key: {\"‚úÖ Configurada\" if api_key else \"‚ùå No configurada\"}')
print(f'Model: {os.getenv(\"OPENAI_MODEL\", \"No configurado\")}')
print(f'Log Level: {os.getenv(\"LOG_LEVEL\", \"No configurado\")}')

print('\\n‚úÖ Diagn√≥stico completado')
"
```

---

**Configuraci√≥n validada**: Todos los entornos (desarrollo, staging, producci√≥n)  
**√öltima actualizaci√≥n**: Septiembre 2025  
**Estado**: ‚úÖ Documentaci√≥n completa y probada